{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skapespeare example\n",
    "\n",
    "**Step 1**: Before all, search \"shakespeare.txt\" on google, download first link and rename to skapespeare.txt.\n",
    "\n",
    "**Step 2**: Load skakespeare complete works to spark context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"/home/adrian/development/spark/notebooks/shakespeare/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Get words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda line: line.split(' ')) \\\n",
    "                .map(lambda word: word.lower()) \\\n",
    "                .filter(lambda word: len(word) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Remove stop words and puctuation symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: sonnets, william, shakespeare, fairest, creatures, desire, increase, beautys, rose, die...\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def strip_punctuation(string):\n",
    "    return ''.join(char for char in string if char not in punctuation)\n",
    "\n",
    "stop_words = [\"i\", \"you\", \"he\", \"she\", \"it\", \"they\", \"we\", \"us\", \"them\", \"him\", \"her\", \"my\", \"your\", \"our\", \"his\", \"its\", \"their\", \"mine\", \"ours\", \"yours\", \"theirs\", \"hers\", \"me\", \"ii\",\"iii\",\"iv\",\"vi\",\"vii\",\"viii\",\"ix\",\"x\",\"xi\",\"xii\",\"xiii\",\"xiv\",\"xv\",\"xvi\",\"xvii\",\"xvii\",\"xviii\",\"xix\",\"xx\", \"one\", \"two\", \"thee\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"will\", \"thy\", \"a\",\"able\",\"about\",\"above\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"after\",\"afterwards\",\"again\",\"against\",\"ah\",\"all\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"announce\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"are\",\"aren\",\"arent\",\"arise\",\"around\",\"as\",\"aside\",\"ask\",\"asking\",\"at\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\"becoming\",\"been\",\"before\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"between\",\"beyond\",\"biol\",\"both\",\"brief\",\"briefly\",\"but\",\"by\",\"c\",\"ca\",\"came\",\"can\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"could\",\"couldnt\",\"d\",\"date\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\"doing\",\"done\",\"don't\",\"down\",\"downwards\",\"due\",\"during\",\"e\",\"each\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"et-al\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"few\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"had\",\"happens\",\"hardly\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"hed\",\"hence\",\"her\",\"here\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hers\",\"herself\",\"hes\",\"hi\",\"hid\",\"him\",\"himself\",\"his\",\"hither\",\"home\",\"how\",\"howbeit\",\"however\",\"hundred\",\"i\",\"id\",\"ie\",\"if\",\"i'll\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"in\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"into\",\"invention\",\"inward\",\"is\",\"isn't\",\"it\",\"itd\",\"it'll\",\"its\",\"itself\",\"i've\",\"j\",\"just\",\"k\",\"keep\tkeeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"m\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"more\",\"moreover\",\"most\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"my\",\"myself\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"no\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"nor\",\"normally\",\"nos\",\"not\",\"noted\",\"nothing\",\"now\",\"nowhere\",\"o\",\"obtain\",\"obtained\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"on\",\"once\",\"one\",\"ones\",\"only\",\"onto\",\"or\",\"ord\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",\"owing\",\"own\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"re\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"s\",\"said\",\"same\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"she\",\"shed\",\"she'll\",\"shes\",\"should\",\"shouldn't\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"such\",\"sufficiently\",\"suggest\",\"sup\",\"sure\tt\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that'll\",\"thats\",\"that've\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"there\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"these\",\"they\",\"theyd\",\"they'll\",\"theyre\",\"they've\",\"think\",\"this\",\"those\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"through\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"until\",\"unto\",\"up\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"very\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasnt\",\"way\",\"we\",\"wed\",\"welcome\",\"we'll\",\"went\",\"were\",\"werent\",\"we've\",\"what\",\"whatever\",\"what'll\",\"whats\",\"when\",\"whence\",\"whenever\",\"where\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whim\",\"whither\",\"who\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whom\",\"whomever\",\"whos\",\"whose\",\"why\",\"widely\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"would\",\"wouldnt\",\"www\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"youd\",\"you'll\",\"your\",\"youre\",\"yours\",\"yourself\",\"yourselves\",\"you've\",\"z\",\"zero\"]\n",
    "\n",
    "words = words.map(lambda word: strip_punctuation(word).strip()) \\\n",
    "             .filter(lambda word: not (word in stop_words or word.isdigit())) \\\n",
    "             .cache()\n",
    "\n",
    "print('Words: ' + ', '.join(words.take(10)) + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Get more popular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|times|\n",
      "+-----+-----+\n",
      "| lord| 3059|\n",
      "| king| 2861|\n",
      "| good| 2812|\n",
      "|  sir| 2754|\n",
      "| well| 2462|\n",
      "|enter| 2098|\n",
      "| love| 2054|\n",
      "|  ill| 1972|\n",
      "| hath| 1941|\n",
      "|  man| 1835|\n",
      "+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from string import punctuation\n",
    "\n",
    "WordSchema = StructType([ \\\n",
    "                StructField('word',  StringType(),  False), \\\n",
    "                StructField('times', IntegerType(), False) \\\n",
    "             ])\n",
    "\n",
    "words_frequency = sqlCtx.createDataFrame(words.map(lambda word: (word, 1)), WordSchema) \\\n",
    "                        .groupBy('word') \\\n",
    "                        .sum('times') \\\n",
    "                        .withColumnRenamed('sum(times)', 'times') \\\n",
    "                        .orderBy(desc('times')) \\\n",
    "                        .cache()\n",
    "\n",
    "words_frequency.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6**: Get diferent words count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferent words count: 27441.\n"
     ]
    }
   ],
   "source": [
    "print('Diferent words count: ' + str(words.distinct().count()) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7**: Get most frequent two letters words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|times|\n",
      "+----+-----+\n",
      "|  ay|  764|\n",
      "|  ye|  289|\n",
      "|  ha|  217|\n",
      "|  ho|  195|\n",
      "|  em|  167|\n",
      "|  de|  115|\n",
      "|  la|   77|\n",
      "|  lo|   74|\n",
      "|  le|   60|\n",
      "|  je|   28|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_frequency.where('length(word)=2').show(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
